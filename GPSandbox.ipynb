{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import george\n",
    "from george.kernels import ExpSquaredKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What's the point here?  \n",
    "#See https://www.overleaf.com/5908814tkxdth#/19548885/ for problem statement\n",
    "#Goals of this hack:\n",
    "##make fake data in the form of true density field with probabilities of galaxy redshifts\n",
    "##generate instantiations of observed density field based on those probabilities\n",
    "##fit gaussian process to density field for each instantiation\n",
    "##combine gaussian process samples to get estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions make observed catalog from true catalog given probabilities\n",
    "\n",
    "def chooser_one(xt,xf,p):\n",
    "    if np.random.uniform() < p:\n",
    "        return xt\n",
    "    return xf\n",
    "\n",
    "def chooser_all(xts,xfs,ps):\n",
    "    output = []\n",
    "    for n in xrange(len(ps)):\n",
    "        output.append(chooser_one(xts[n],xfs[n],ps[n]))\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try bigger samples!\n",
    "ngals = 100\n",
    "nsurvs = 10\n",
    "\n",
    "#make the probabilities, could be smarter\n",
    "p = np.random.rand(ngals)\n",
    "\n",
    "#choose density measurement locations\n",
    "#there's actually no reason for these to be randomly sampled if they represent density values\n",
    "xt = 10 * np.sort(np.random.rand(ngals))\n",
    "\n",
    "#fake redshifts\n",
    "#try different prescriptions for this\n",
    "xf = 10 * np.random.rand(ngals)\n",
    "\n",
    "#errors on densities\n",
    "#there's no reason the errors have to be the same\n",
    "yerr = 0.2 * np.ones_like(xt)\n",
    "\n",
    "#try different functions here, something realistic for density field\n",
    "y = np.sin(xt) + yerr * np.random.randn(len(xt))\n",
    "\n",
    "#instantiations of the survey\n",
    "xos = [chooser_all(xt,xf,p) for n in xrange(nsurvs)]\n",
    "\n",
    "#plt.plot(xf,y)\n",
    "for xo in xos:\n",
    "    plt.plot(xo,y,'ro',alpha=1./nsurvs)\n",
    "#plt.legend()\n",
    "#print(p)\n",
    "plt.plot(xt,y,'bo')\n",
    "plt.savefig('inputs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stolen wholesale from DFM's documentation\n",
    "#http://dan.iel.fm/george/current/user/quickstart/#a-simple-example\n",
    "\n",
    "# Set up the Gaussian process.\n",
    "kernel = ExpSquaredKernel(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_tru = george.GP(kernel)\n",
    "\n",
    "# Pre-compute the factorization of the matrix.\n",
    "gp_tru.compute(xt, yerr)\n",
    "\n",
    "# Compute the log likelihood.\n",
    "print(gp_tru.lnlikelihood(y))\n",
    "\n",
    "gp_obss = [george.GP(kernel) for n in xrange(nsurvs)]\n",
    "\n",
    "# Pre-compute the factorization of the matrix.\n",
    "for n in xrange(nsurvs):\n",
    "    gp_obss[n].compute(xos[n], yerr)\n",
    "    # Compute the log likelihood.\n",
    "    print(gp_obss[n].lnlikelihood(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.linspace(0, 10, 500)\n",
    "\n",
    "mu_tru, cov_tru = gp_tru.predict(y, t)\n",
    "std_tru = np.sqrt(np.diag(cov_tru))\n",
    "\n",
    "mu_obss,cov_obss = [],[]\n",
    "for n in xrange(nsurvs):\n",
    "    mu_obs, cov_obs = gp_obss[n].predict(y, t)\n",
    "    mu_obss.append(mu_obs)\n",
    "    cov_obss.append(cov_obs)\n",
    "    #std_obs = np.sqrt(np.diag(cov_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsamps = 3\n",
    "toplot_tru = np.random.multivariate_normal(mu_tru,cov_tru,nsamps)\n",
    "toplot_obss = [np.random.multivariate_normal(mu_obss[n],cov_obss[n],nsamps) for n in xrange(nsurvs)]\n",
    "for s in xrange(nsamps):\n",
    "    plt.plot(t,toplot_tru[s],c='b')\n",
    "for n in xrange(nsurvs):\n",
    "    for s in xrange(nsamps):\n",
    "        plt.plot(t,toplot_obss[n][s],c='r',alpha=1./nsamps)\n",
    "    plt.plot(xos[n],y,'ro',alpha=1./nsurvs)\n",
    "plt.plot(xt,y,'bo')\n",
    "plt.savefig('outputs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how to combine posterior samples from different survey instantiations?\n",
    "#importance sampling, jackknifing, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
